ngnix

事件驱动
主进程（读取配置+绑定端口）+一系列工作进程+辅助进程
进程切换消耗内存
主进程 创建三个子进程 缓存加载+缓存管理+工作进程 1cpu1进程
工作进程 等待套接字等待事件 
fork一个新的工作进程，旧的慢慢退出舞台
核心模块+基础模块+第三方模块
handler 模块+filter模块+proxy模块 
单进程= 主+工作1个 工作进程是单线程。  默认的
多进程=主+工作进程  工作进程 是多线程的
平滑的重启  新的出来，老的同时退休，服务不停止
一个请求在一个工作进程处理，有锁互斥，然后处理完断开
负载均衡
轮询，权重，ip_hash,url_hash,fair 响应时间
独立的进程不用加锁。
异步非阻塞形式
请求过来，系统读写事件，没准备好，不可操作，ngnix全部使用非阻塞，先给你结果，然后过来，非阻塞，得没事检查一下，或者主动通知。消费事件对列
https://blog.csdn.net/jaryn_fang/article/details/80754445  配置大全

缓存使用
设置过期时间，是最终一致性解决方案，写操作以数据库为准，写ok，缓存不ok，但过期时间后，自然还是ok的
1 更新数据库，再更新缓存
不考虑，线程安全。a b a更新数据库，b更新数据库，b更新缓存，a更新缓存，顺序乱了，脏数据
2先删除缓存，在更新数据库
a 更新
b 查询
a 写，删除缓存-b发现缓存不存在-b去查数据库发现旧值-b将旧值写入缓存-a将新值写入数据库
采用延时双删策略
先删缓存-写数据库-休眠一秒-再次淘汰缓存，具体休眠看实际需要
分离策略，就是主从还没有同步，那么还是采用这个策略，将同步时间加进去
吞吐量降低？
第二次删除作为异步，自己起一个线程，异步删除，写的请求就不用沉睡一段时间了，再返回，这么做，加大吞吐量
第二次删除失败了？
缓存和数据库依然不一致，怎么办？采用下面的第三种策略
3先更新数据库，再删缓存
缓存刚好失效-a去查旧值-b将新值写入-b删除缓存-a将旧值写入缓存 这是不可能的，因为读远远比写快

重试机制
1使用消息队列，删除的key放入队列，自己消费信息，继续重试删除操作直到成功。
2另起一个程序，去订阅数据库的binlog，获得需要的数据，然后删除缓存操作
更新数据库-数据库操作信息写入binlog日志中-订阅程序取出需要的数据以及key-另起一个非业务代码，获得该信息-尝试删除操作，发现删除失败-将信息发送至队列-重新获得该数据，重试操作


zookeeper

1简介说明

1分布式协调服务，暴露了一些公用服务，命名，配置管理，同步控制，群组服务。存一些配置想你想
反应给服务器，zk实现共识，集群管理，leader选择
2基于ZAB算法，分布式一致性问题的利器，最好是奇数个
顺序一致性：一个客户端发起请求，严格按照顺序。zookeeper是一个整体，保证三者数据一致，有锁里额 
原子性：要么整个集群所有机器应用一个事务，要么不应用
单一视图：无论连接谁，所有服务端数据一致
可靠性：一旦服务器应用一个事务，并完成对客户端的相应，那么该事务状态保留下来，除非有
另一个事务去更改，数据同步不成功，那么就一直等着，挂掉一半以上就不提供服务了
实时性：一旦事务应用，立即获取变更后的数据，仅仅能保证在一段时间内，客户端最终能一定能从
服务端读取最新的数据状态
3目标1 简单数据结构，树形
构建集群：半数以上就可以提供服务
高性能：存在内存中，并直接服务于所有的非事务性请求，以读操作性能很高。
4结构其实是树形结构，标准的文件系统
znode节点可以是临时的，可以被监控
5组成，leader follower observer
observer特殊的follower，可以接受reader请求，但不参与选举，只负责于leader同步数据
2x搭建zookeeper与配置文件说明
3java操作zookeeper
4应用场景
基于观察者模式的设计的分布式服务管理框架，负责存储和管理大家都关心的数据
接受观察者注册，一旦数据状态发生变化，zookeeper就负责通知以及在zookker上注册
的那些观察者做出相应的反应，以实现集群中类似master/slave的模式
1配置管理 数据量小，内容运行时发生变化，各个节点共享信息，配置一致
2集群管理 希望知道有多少机器工作，对每天集群的运行时的状态数据收集，每台集群进行上下线操作
3发布与订阅  dubbo
4数据库切换		初始化zookeeper读取一个节点上配置文件，当配置一旦便跟个，通知发送给各个客户端，每个互动接受变
通知后，就可以从最新的数据的获取
5分布式日志的收集 
6分布式锁，队列管理
5zkClient客户端
6Curator框架
原生api太复杂，可以用完美的第三方解决，就是这个框架 ,apache顶级项目
分布式进行master选举解决单点故障，保证每时每刻都有一个master来为分布式提供服务

模式1 独立模式 只有一个zookeeper
2集群模式
从节点都是主节点的副本。

读写机制
核心是非锁机制wait free的同步核心机制。对文件读写并不加锁。
1全局串行化的写操作，读请求由本地响应，所有的更新请求转发给leader，由leader实施

写请求到leader，foller接受leader发来的提议消息。

cap理论
一致性分类
强一致
单调一致
会话一致
最终一致，需要时间去同步
弱一致

使用顺序一致性 严格按照操作顺序，原子性，单一系统映像（任何一个客户端看到的到是一个整体），持久性
zab广播协议
1恢复模式
就是选举后，然后同步完成，恢复模式才结束
1不能遗忘以及被deliver的消息，该消息在每台都要deliver即使故障了，只要发出去，那么即使故障，恢复了也要出来，如果没发出去就故障，那么该忽略掉
2必须丢弃以及被skip的消息

2广播模式
leader一直在广播，除非leader崩了 类似于俩阶段提交
leader提交一个决议，然后foller进行投票，要么通过然后做，要么不通过什么都不做
顺序核心是进行队列输送。
leader会广播以及被deliver的proposal的消息，在发出proposal的消息前会分配一个id，foller接收到这个消息时，会写入磁盘，会发送ack给leader，当leader收到指定的ack时，leader将
广播commit，foller会提交该消息。




分布式事务
1俩阶段
准备阶段
事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。

可以进一步将准备阶段分为以下三个步骤：

1）协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。

2）参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作）

3）各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。
2提交阶段
1）协调者节点向所有参与者节点发出”正式提交(commit)”的请求。

2）参与者节点正式完成操作，并释放在整个事务期间内占用的资源。

3）参与者节点向协调者节点发送”完成”消息。

4）协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。
1、同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。

2、单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）

3、数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。

4、二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。

2三阶段 引入超时机制
1cancommit
1.事务询问 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。

2.响应反馈 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No
2precommit
1.发送预提交请求 协调者向参与者发送PreCommit请求，并进入Prepared阶段。

2.事务预提交 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。

3.响应反馈 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。
3docommit
1.发送中断请求 协调者向所有参与者发送abort请求。

2.中断事务 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。
在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。 ）
相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。

了解了2PC和3PC之后，我们可以发现，无论是二阶段提交还是三阶段提交都无法彻底解决分布式的一致性问题。Google Chubby的作者Mike Burrows说过， there is only one consensus protocol, and that’s Paxos” C all other approaches are just broken versions of Paxos. 意即世上只有一种一致性算法，那就是Paxos，所有其他一致性算法都是Paxos算法的不完整版。后面的文章会介绍这个公认为难于理解但是行之有效的Paxos算法。

redis锁

1同一资源并发请求，加锁
2一直加循环加锁，直到获取到才返回结果，悲观锁
3获取玩锁就特定值加1，执行完对特定值进行释放，抛出异常要释放，finally块释放锁
4就算加了finally还是挂了，对锁就超时时间
5锁时间比业务短，出现线程重复进入，对redis的锁进行uuid，释放时，要id匹配才能释放，另外开一个线程，检查锁，没失效就加五秒，保持有效性，
6redis主从切换，从节点重新上锁

tomcat架构

1server - 多个service 
service - 多个connector + 1 container
connector对socket和request进行封装和转化 多个就是不同协议的连接
container  进行是servlet的容器 = 1engine
引擎= 多个host
host = 多个context
context = 多个wrapper 就是servlet容器
connetor是一个协议处理器，由endpoint（处理底层的socket连接）
container采用管道模式，一层层处理
生命周期由server控制
server.xml中进行控制

mybatis架构
反射模块 类型转换模块 日志模块 资源加载模块 解析器模块
配置解析-参数映射-sql解析-sql执行-结果集映射-插件
数据源模块-事务管理模块-缓存模块-binding模块-反射模块-类型转换-日志模块-资源加载-解析器模块

中间件

数据丢失问题？
rabbitmq
使用事务功能，如果消息没有被接受到，生产者会报异常，然后事务回滚，然后重试发送，然后提交事务，但是事务是同步的，会降低性能
使用confirm模式，分配一个id，接受成功会返回ack，没能处理，则会调用回调接口，也可以设置超时状态，然后重发，这个是异步的。
mq自己丢失数据，则使用持久化，会持久化到磁盘，重启会恢复。持久化过程宕机，会数据丢失，可以配合生产者，持久化成功，才返回ack信息，然后重发，这个是异步的。
消费者如果丢失，则使用ack机制，自己ack，mq则不会删除消息

kafka
消费弄丢数据，
kafka会自动提交offset，那关闭自动提交好了，如果重复消费，自己保持冥等性。
kafka的leader宕机，重新选举成为leader时，数据丢失？
设置一些参数即可，保持副本跟随，每条数据写入所有副本才算写成功，一旦写入失败，则无限重试

分布式场景中，最终一致性？
1先执行数据库，发送消息，order新增成功，消息发送失败，不一致
2先发消息，在数据库
消息成功，数据库失败
3在数据库事务中，发送消息，在数据库
数据库ok，消息以及发送，无法进行回滚
4在事务中，先数据库，然后发送消息
成功与否，应答机制和事务机制
如果response失败，则回滚事务，网络原因没有及时接受到消息，
使用中间件的事务机制
5队列不支持事务
新增一张表，定时任务扫描这张表，将所有prepared状态的消息发给队列，成功后，改为confirmed
如何保证重复消费呢，在建一个表，来判断是否消费过，如果消费多，直接放弃

一致性6中解决方案
问题的起源

在电商等业务中，系统一般由多个独立的服务组成，如何解决分布式调用时候数据的一致性？ 

具体业务场景如下，比如一个业务操作，如果同时调用服务 A、B、C，需要满足要么同时成功；要么同时失败。A、B、C 可能是多个不同部门开发、部署在不同服务器上的远程服务。

在分布式系统来说，如果不想牺牲一致性，CAP 理论告诉我们只能放弃可用性，这显然不能接受。为了便于讨论问题，先简单介绍下数据一致性的基础理论。

1. 规避分布式事务――业务整合

业务整合方案主要采用将接口整合到本地执行的方法。拿问题场景来说，则可以将服务 A、B、C 整合为一个服务 D 给业务，这个服务 D 再通过转换为本地事务的方式，比如服务 D 包含本地服务和服务 E，而服务 E 是本地服务 A ~ C 的整合。

优点：解决（规避）了分布式事务。

缺点：显而易见，把本来规划拆分好的业务，又耦合到了一起，业务职责不清晰，不利于维护。

由于这个方法存在明显缺点，通常不建议使用。  https://www.cnblogs.com/soundcode/p/5590710.html

京东案例  https://blog.csdn.net/g1607058603/article/details/81462162
https://blog.csdn.net/z_565282532/article/details/79051670
分布式事务解决方案：补偿机制TCC、XA、消息队列MQ。

数据库undo 和 redo问题（log也是缓存）
undo记录修改前的值，redo记录修改后的值，redo日志先持久化到磁盘上，然后事务操作结果写入db buffer （缓存），当db buffer满了以后才会写入最终的data file


mysql数据库事务的实现原理
RAED UNCOMMITED：读未提交，任何操作都不加锁，所以能读到其他事务修改但未提交的数据行，也称之为脏读（Dirty Read）；
READ COMMITED：读操作不加锁，写操作加锁。读被加锁的数据时，读事务每次都读undo log中的最近版本，因此可能对同一数据读到不同的版本（不可重复读），但能保证每次都读到最新的数据（事务提交之后的，不可重复读，两次读不一致），但是不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近，所以再多次使用查询语句时，可能得到不同的结果（Non-Repeatable Read）；
REPEATABLE READ：第一次读数据的时候就将数据加行锁（共享锁），使其他事务不能修改当前数据，即可实现可重复读。但是不能锁住insert进来的新的数据，当前事务读取或者修改的同时，另一个事务还是可以insert提交，造成幻读；
（注：mysql的可重复读的隔离级别解决了 “不可重复读” 和 “幻读” 2个问题，因为使用了间隙锁，下文讲解）
SERIALIZABLE：InnoDB 锁表，读锁和写锁阻塞，强制事务串行执行，解决了幻读的问题；
可见不同的隔离级别，对于读写事务是否加锁进行了限定，而不同的锁，对于数据库的事务的并发性能的影响，是不一样的，这里对于性能、一致性进行了对比，由此看出他们之间的关系：
性能：读未提交>读提交>可重复读>串行化
一致性:串行化>可重复读>读提交>读未提交
共享锁：即读加锁，不能写并且可并行读
排它锁:写加锁，其他读写都阻塞
表锁：锁 整个表，性能开销最大，其他的读写都要挂起
行锁：锁整个行，以默认隔离级别为例：如果是读，那么会上共享锁，不允许写，如果是写，那么改行其他事务无论读写都得阻塞
间隙锁：间隙锁分为两种，一种是不包含记录间隙锁(GAP)，一种是包含记录间隙锁（Next-Key Lock: Gap Lock+Record Lock），比如对于默认隔离级别的innoDB下, 比如表A 上的id字段有索引, 并且id有 3,8,12,20这几个值,那么该索引可能被上的包含记录间隙锁区间为:(负无穷,3)、[3,8)、[8,12)、[12,20)、[20,正无穷)
https://blog.csdn.net/qq_35571554/article/details/82392405

Rpc
Q:讲一下Dubbo
服务提供者提供服务，服务消费者可以通过Rpc进行服务消费。
Q:Dubbo支持哪些协议？
Dubbo支持Dubbo、rmi、hessian、http、webservice、thrift、Redis等多种协议
Q:Dubbo默认的协议是什么？
Dubbo协议。
Q:Dubbo的序列化有哪些方式？
Dubbo协议。
连接方式：长连接。默认协议：dubbo协议。序列化：hession二进制。
其他协议：
rmi协议。连接方式：短连接。序列化：java自带的二进制
hessian。连接方式：短连接。序列化：表单序列化
Q:Dubbo和SpringCloud有哪些区别？
Dubbo是Soa(面向服务的架构)，SpringCloud是微服务架构，除了服务，还有注册中心、熔断、配置中心。
Dubbo基于Rpc(远程过程调用)，SpringCloud基于restFul，基于http协议。
Q:Soa和微服务架构，有哪些区别？
https://blog.csdn.net/zpoison/article/details/80729052
Q:除了Zookeeper，你用过哪些注册中心?有什么区别？
Zookeeper，Redis，Eureka
Zookeeper，是分布式中的CP，能够更好地保证分布式一致性。
Redis基于发布/订阅模式。
Eureka在SpringCloud中应用较多。Eureka是分布式中的AP，也就是注重可用性。
Q:如果想实现一个Rpc框架，需要考虑哪些东西？
动态代理、反射、序列化、反序列化、网络通信(netty)、编解码、服务发现和注册、心跳与链路检测
Q:Dubbo的服务提供者、服务消费者需要配置哪些信息？
服务提供者需要配置ip、端口、Dubbo协议、注册中心地址等
Q:Dubbo有哪些负载均衡策略？
一致性Hash均衡算法、随机调用法、轮询法、最少活动调用法。
Q:你们用的是哪个版本的Dubbo?
Q:你们的服务划分了几个模块？分别是哪些模块？

Redis
Q:Redis有哪些优势？
1.速度快，因为数据存在内存中
2.支持丰富数据类型，支持string，list，set，sorted set，hash
3.支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
4.丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除
5.单线程，单进程，采用IO多路复用技术。
Q:Redis支持哪些数据结构？
string(字符串),hash(哈希),list(队列),set(集合)及zset(sorted set:有序集合)。
Q:Redis的数据结构，有哪些应用场景？
string，简单地get/set缓存。
hash，可以缓存用户资料。比如命令： hmset user1 name "lin" sex "male" age "25" ，缓存用户user1的资料，姓名为lin，性别为男，年龄25。
list，可以做队列。往list队列里面push数据，然后再pop出来。
zset，可以用来做排行榜。
详情见：https://www.cnblogs.com/expiator/p/10274151.html
Q:Redis的持久化方式有哪些？有哪些优缺点？
https://blog.csdn.net/xsj_blog/article/details/70495456
aof，就是备份操作记录。aof由于是备份操作命令，备份快，恢复慢。
rdb，就是备份所有数据，使用了快照。rdb恢复数据比较快。
Q:aof文件过大，怎么处理？
会进行aof文件重写。
1.随着AOF文件越来越大，里面会有大部分是重复命令或者可以合并的命令
2.重写的好处：减少AOF日志尺寸，减少内存占用，加快数据库恢复时间。
执行一个 AOF文件重写操作，重写会创建一个当前 AOF 文件的体积优化版本。
详情见： https://blog.csdn.net/stevendbaguo/article/details/82855726
Q:讲一下Redis的事务
先以 MULTI 开始一个事务， 然后将多个命令入队到事务中， 最后由 EXEC 命令触发事务， 一并执行事务中的所有命令。如果想放弃这个事务，可以使用DISCARD命令。
Redis事务无法回滚，那怎么处理？
Q:怎么设置Redis的key的过期时间？
key的的过期时间通过EXPIRE key seconds命令来设置数据的过期时间。返回1表明设置成功，返回0表明key不存在或者不能成功设置过期时间。
Q:Redis的过期策略有哪些？
Redis key过期的方式有三种：
被动删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key
主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key
当前已用内存超过maxmemory限定时，触发主动清理策略，也就是Redis的内存回收策略。
Q:Redis 的内存回收机制都有哪些？
LRU、TTL。
noeviction：默认策略，不会删除任何数据，拒绝所有写入操作并返回客户端错误信息，此时Redis只响应读操作。
volatitle-lru：根据LRU算法删除设置了超时属性的键，知道腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略。
allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。
allkeys-random：随机删除所有键，知道腾出足够空间为止。
volatitle-random：随机删除过期键，知道腾出足够空间为止。
volatitle-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略
Q:手写一下LRU算法 。
Q:Redis如何实现分布式锁？
使用setnx命令。
setnx key value，当key不存在时，将 key 的值设为 value ，返回1。若给定的 key 已经存在，则setnx不做任何动作，返回0。
当setnx返回1时，表示获取锁，做完操作以后del key，表示释放锁，如果setnx返回0表示获取锁失败。
Q:Redis实现的分布式锁，如果某个系统获取锁后，宕机了怎么办？
Redis宕机的话，会通过Redis集群的哨兵模式，将某个从机变成新的主机。
系统模块宕机的话，可以通过设置过期时间(就是设置缓存失效时间)解决。系统宕机时锁阻塞，过期后锁释放。
Q:设置缓存失效时间，那如果前一个线程把这个锁给删除了呢？
Q:Redis做分布式锁，Redis做了主从，如果设置锁之后，主机在传输到从机的时候挂掉了，从机还没有加锁信息，如何处理？
可以使用开源框架Redisson，采用了redLock。(待补充)
Q:讲一下Redis的redLock。
Q:Redis的搭建有哪些模式？
主从模式、哨兵模式、Cluster（集群）模式。
最好是用集群模式。
详情见：https://new.qq.com/omn/20180126/20180126G00THE.html
Q:你用过的Redis是多主多从的，还是一主多从的？集群用到了多少节点？用到了多少个哨兵？
集群模式。三主三从。
Q:Redis采用多主多从的集群模式，各个主节点的数据是否一致？
Q:Redis集群有哪些特性？
master和slaver。主从复制。读写分离。哨兵模式。
Q:Redis集群数据分片的原理是什么？
Redis数据分片原理是哈希槽。
Redis 集群有 16384 个哈希槽。 每一个 Redis 集群中的节点都承担一个哈希槽的子集。
哈希槽让在集群中添加和移除节点非常容易。例如，如果我想添加一个新节点 D，我需要从节点 A，B， C 移动一些哈希槽到节点 D。同样地，如果我想从集群中移除节点 A，我只需要移动 A 的哈希槽到 B 和 C。 当节点 A 变成空的以后，我就可以从集群中彻底删除它。 因为从一个节点向另一个节点移动哈希槽并不需要停止操作，所以添加和移除节点，或者改变节点持有的哈希槽百分比，都不需要任何停机时间(downtime)。
Q:集群的拓扑结构有没有了解过？集群是怎么连接的？
无中心结构。Redis-Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。
Q:讲一下Redis主从复制的过程。
从机发送SYNC(同步)命令，主机接收后会执行BGSAVE(异步保存)命令备份数据。
主机备份后，就会向从机发送备份文件。主机之后还会发送缓冲区内的写命令给从机。
当缓冲区命令发送完成后，主机执行一条写命令，就会往从机发送同步写入命令。
更详细的步骤见： https://www.cnblogs.com/expiator/p/9881989.html
Q:讲一下Redis哨兵机制。
下面是Redis官方文档对于哨兵功能的描述：
监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。
自动故障转移（Automatic Failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。
配置提供者（Configuration Provider）：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。
通知（Notification）：哨兵可以将故障转移的结果发送给客户端。
Zookeeper
Q:Zookeeper的原理是什么？
zab协议。
zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，zab就进入了恢复模式，当领导者被选举出来，且大多数server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和server具有相同的系统状态。
Q:Zookeeper有哪些应用场景？
Zookeeper可以作为服务协调的注册中心。还可以做分布式锁(如果没有用过分布式锁就不要说)
Q:Zookeeper为什么能做注册中心？
Zookeeper的数据模型是树型结构，由很多数据节点组成，zk将全量数据存储在内存中，可谓是高性能，而且支持集群，可谓高可用，另外支持事件监听(watch命令)。这些特点决定了zk特别适合作为注册中心
Q:Zookeeper的节点有哪些类型？有什么区别？
临时节点，永久节点。 更加细分就是临时有序节点、临时无序节点、永久有序节点、永久无序节点。　　
临时节点： 当创建临时节点的程序停掉之后，这个临时节点就会消失，存储的数据也没有了。
Q:Zookeeper做为注册中心，主要存储哪些数据？
ip、端口，还有心跳机制。
Q:心跳机制有什么用？
Q:Zookeeper的广播模式有什么缺陷？
广播风暴。
Q:Zookeeper是怎么实现分布式锁的？
分布式锁：基于Zookeeper一致性文件系统,实现锁服务。锁服务分为保存独占及时序控制两类。
保存独占：将Zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除自己创建的distribute_lock 节点就释放锁。
时序控制：基于/distribute_lock锁，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。
更详细的回答如下：
其实基于Zookeeper，就是使用它的临时有序节点来实现的分布式锁。
原理就是：当某客户端要进行逻辑的加锁时，就在Zookeeper上的某个指定节点的目录下，去生成一个唯一的临时有序节点， 然后判断自己是否是这些有序节点中序号最小的一个，如果是，则算是获取了锁。如果不是，则说明没有获取到锁，那么就需要在序列中找到比自己小的那个节点，并对其调用exist()方法，对其注册事件监听，当监听到这个节点被删除了，那就再去判断一次自己当初创建的节点是否变成了序列中最小的。如果是，则获取锁，如果不是，则重复上述步骤。
当释放锁的时候，只需将这个临时节点删除即可。
Q:讲一下Zookeeper的读写机制。Zookeeper是怎么保持一致性的？
Leader主机负责读和写。
Follower负责读，并将写操作转发给Leader。Follower还参与Leader选举投票，参与事务请求Proposal投票。
Observer充当观察者的角色。Observer和Follower的唯一区别在于：Observer不参与任何投票。
Q:讲一下Zookeeper的选举机制。
Leader不可用时，会重新选举Leader。超过半数的Follower选举投票即可，Observer不参与投票。
Q:你们的zookeeper集群配置了几个节点？
3个节点。注意，zookeeper集群节点，最好是奇数个的。
集群中的zookeeper节点需要超过半数，整个集群对外才可用。
这里所谓的整个集群对外才可用，是指整个集群还能选出一个Leader来，zookeeper默认采用quorums来支持Leader的选举。
如果有2个zookeeper，那么只要有1个死了zookeeper就不能用了，因为1没有过半，所以2个zookeeper的死亡容忍度为0；同理，要是有3个zookeeper，一个死了，还剩下2个正常的，过半了，所以3个zookeeper的容忍度为1；同理你多列举几个：2->0;3->1;4->1;5->2;6->2会发现一个规律，2n和2n-1的容忍度是一样的，都是n-1，所以为了更加高效，何必增加那一个不必要的zookeeper呢。

消息队列
Q:为什么使用消息队列？消息队列有什么优点和缺点？Kafka、ActiveMQ、RabbitMq、RocketMQ 都有什么优点和缺点？
消息队列解耦，削峰，限流。
https://www.jianshu.com/p/eaafb1581e55
Q:如何保证消息队列的高可用？
https://blog.csdn.net/u014801403/article/details/80312677
Q:如何保证消息不被重复消费？（如何保证消息消费的幂等性）
https://www.jianshu.com/p/62df9975e7dc
Q:如何保证消息的可靠性传输？（如何处理消息丢失的问题）
https://www.jianshu.com/p/4491cba335d1
https://blog.csdn.net/qq_42914528/article/details/90627277 消费者消费失败怎么办
Q:如何保证消息的顺序性？
https://www.jianshu.com/p/8a5630e2c317
Q:如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？
https://www.jianshu.com/p/5f4b3a520719
Q:如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路。
https://www.jianshu.com/p/d0784dab9b84

Kafka
Q:讲一下Kafka。
Kafka的简单理解
Q:Kafka作为消息队列，有哪些优势？
https://www.cnblogs.com/expiator/p/9713433.html
分布式的消息系统。
高吞吐量。即使存储了许多TB的消息，它也保持稳定的性能。
数据保留在磁盘上，因此它是持久的。
Q:Kafka的偏移量是什么？
消费者每次消费数据的时候，消费者都会记录消费的物理偏移量（offset）的位置。等到下次消费时，他会接着上次位置继续消费
Q:Kafka的消费者群组Consumer Group订阅了某个Topic，假如这个Topic接收到消息并推送，那整个消费者群组能收到消息吗？
http://kafka.apache.org/intro
Kafka官网中有这样一句"Consumers label themselves with a consumer group name, and each record published to a topic is delivered to one consumer instance within each subscribing consumer group. "
表示当topic上的record被发送到已订阅的消费者群组里面的一个消费者实例。
Q:Kafka为什么要分区？
实现负载均衡和水平扩展。
Kafka可以将主题(Topic)划分为多个分区（Partition），会根据分区规则选择把消息存储到哪个分区中，只要如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡和水平扩展。另外，多个订阅者可以从一个或者多个分区中同时消费数据，以支撑海量数据处理能力。
Q:Kafka如何保证消息的顺序性？
Kafka 可以保证同一个分区里的消息是有序的。也就是说消息发送到一个Partition 是有顺序的。
Q:Kafka消息消费者宕机了，怎么确认有没有收到消息？
ack机制，如果接收方收到消息后，会返回一个确认字符。
Q:讲一下Kafka的ack机制。
request.required.acks有三个值 0 1 -1
0:生产者不会等待broker的ack，这个延迟最低但是存储的保证最弱当server挂掉的时候就会丢数据
1：服务端会等待ack值 leader副本确认接收到消息后发送ack但是如果leader挂掉后他不确保是否复制完成新leader也会导致数据丢失
-1：同样在1的基础上 服务端会等所有的follower的副本受到数据后才会受到leader发出的ack，这样数据不会丢失
仅设置acks=-1也不能保证数据不丢失，当Isr列表中只有Leader时，同样有可能造成数据丢失。要保证数据不丢除了设置acks=-1, 还要保证ISR的大小大于等于2，具体参数设置：
request.required.acks：设置为-1 等待所有ISR列表中的Replica接收到消息后采算写成功；
min.insync.replicas: 设置为大于等于2，保证ISR中至少有两个Replica
Q:Kafka如何避免消息丢失？
Q:Kafka怎么保证可靠性？(存疑)
在Kafka中主要通过ISR机制来保证消息的可靠性。
ISR（in sync replica）：是Kafka动态维护的一组同步副本，在ISR中有成员存活时，只有这个组的成员才可以成为leader，内部保存的为每次提交信息时必须同步的副本（acks = all时），每当leader挂掉时，在ISR集合中选举出一个follower作为leader提供服务，当ISR中的副本被认为坏掉的时候，会被踢出ISR，当重新跟上leader的消息数据时，重新进入ISR。
详情见： https://www.jianshu.com/p/ebeaa7593d83
Q:Kafka怎么保证一致性？(存疑)
一致性定义：若某条消息对client可见，那么即使Leader挂了，在新Leader上数据依然可以被读到。
HW-HighWaterMark: client可以从Leader读到的最大msg offset，即对外可见的最大offset， HW=max(replica.offset)
对于Leader新收到的msg，client不能立刻消费，Leader会等待该消息被所有ISR中的replica同步后，更新HW，此时该消息才能被client消费，这样就保证了如果Leader fail，该消息仍然可以从新选举的Leader中获取。
对于来自内部Broker的读取请求，没有HW的限制。同时，Follower也会维护一份自己的HW，Folloer.HW = min(Leader.HW, Follower.offset)
详情见：https://www.jianshu.com/p/f0449509fb11
Q:Kafka怎么处理重复消息？怎么避免重复消费？
一般情况下，kafka重复消费都是由于未正常提交offset造成的。
使用的是spring-Kafka，所以把Kafka消费者的配置enable.auto.commit设为false，禁止Kafka自动提交offset，从而使用spring-Kafka提供的offset提交策略。spring-Kafka中的offset提交策略可以保证一批消息数据没有完成消费的情况下，也能提交offset，从而避免了提交失败而导致永远重复消费的问题。
如何去重：将消息的唯一标识保存起来，每次消费时判断是否处理过即可。
Q:Kafka消息是采用pull模式，还是push模式？
pull模式。
Q:pull模式和push模式，各有哪些特点？
pull模式，准确性？可以较大保证消费者能获取到消息。
push模式，即时性？可以在broker获取消息后马上送达消费者。
Q:讲一下Kafka集群的Leader选举机制。
Kafka在Zookeeper上针对每个Topic都维护了一个ISR（in-sync replica---已同步的副本）的集合，集合的增减Kafka都会更新该记录。如果某分区的Leader不可用，Kafka就从ISR集合中选择一个副本作为新的Leader。

分库分表
Q:数据库如何处理海量数据？
分库分表，主从架构，读写分离
Q:数据库分库分表，何时分？怎么分？
水平分库/分表，垂直分库/分表
水平分库/表，各个库和表的结构一模一样。
垂直分库/表，各个库和表的结构不一样。
Q:读写分离怎么做？
主机负责写，从机负责读。

分布式、高并发场景
Q:在实践中，遇到过哪些并发的业务场景？
秒杀。比如抢商品，抢红包。
Q:如何设计一个秒杀/抢券系统？
可以通过队列配合异步处理实现秒杀。
使用redis的list，将商品push进队列，pop出队列。
异步操作不会阻塞，不会消耗太多时间。
Q:如何提高抢券系统的性能？
使用多个list。
使用多线程从队列中拉取数据。
集群提高可用性。
MQ异步处理，削峰。
Q:秒杀怎么避免少卖或超卖？
redis是单进程单线程的，操作具有原子性，不会导致少卖或者超卖。
另外，也可以设置一个版本号version，乐观锁机制。

mybatis技术
https://www.cnblogs.com/chongaizhen/p/11170595.html 架构
https://cloud.tencent.com/developer/article/1432278 架构
缓存
https://www.jianshu.com/p/f705fa21f271
sqlSession2更新了id为1的学生的姓名，从凯伦改为了小岑，但session1之后的查询中，id为1的学生的名字还是凯伦，出现了脏数据，也证明了之前的设想，一级缓存只在数据库会话内部共享。
当sqlsession没有调用commit()方法时，二级缓存并没有起到作用。
我们可以看到，在sqlSession3更新数据库，并提交事务后，sqlsession2的StudentMapper namespace下的查询走了数据库，没有走Cache。
4.5 总结
MyBatis的二级缓存相对于一级缓存来说，实现了SqlSession之间缓存数据的共享，同时粒度更加的细，能够到namespace级别，通过Cache接口实现类不同的组合，对Cache的可控性也更强。
MyBatis在多表查询时，极大可能会出现脏数据，有设计上的缺陷，安全使用二级缓存的条件比较苛刻。
在分布式环境下，由于默认的MyBatis Cache实现都是基于本地的，分布式环境下必然会出现读取到脏数据，需要使用集中式缓存将MyBatis的Cache接口实现，有一定的开发成本，直接使用Redis、Memcached等分布式缓存可能成本更低，安全性也更高。

spring缓存
https://www.cnblogs.com/fysola/p/6378400.html

基于类的缓存，将会缓存类中的所有方法，缓存之后，程序调用该类实例的任何方法，只要传入的参数相同，Spring将不会真正执行该方法，而是直接根据传入的参数去查找缓存中的数据！
上面的ehcache.xml配置了两个缓存区，Spring中的Bean将会缓存在这些缓存区中，一般的，Spring容器中有多少个Bean，就会在ehcache中定义多少个缓存区。

接着在Spring配置文件中配置缓存管理器如下，其中第一个Bean是一个工厂Bean，用来配置EhCache的CacheManager, 第二个Bean才是为Spring缓存配置的缓存管理器，所以将第一个Bean注入第二个Bean。
基于类的缓存，将会缓存类中的所有方法，缓存之后，程序调用该类实例的任何方法，只要传入的参数相同，Spring将不会真正执行该方法，而是直接根据传入的参数去查找缓存中的数据！
方法级别的缓存
方法级别的缓存则只会对方法起作用了，不同的方法可以设置不用的缓存区，例如下面这样，
测试时，访问index.jsp之后点击各个链接并依次观察控制台输出即可
缓存有效果的特征是：第二次查询数据时不会访问数据库（即不打印日志）

 js执行顺序
https://juejin.im/post/59e85eebf265da430d571f89


nodeJs原理
https://blog.csdn.net/yezhenxu1992/article/details/51731237

netty工作架构
https://blog.csdn.net/u013967628/article/details/84293834